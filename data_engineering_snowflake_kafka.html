<!DOCTYPE HTML>
<html>
	<head>
		<title>Paul Hankins</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/themes/prism-dark.min.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/plugins/toolbar/prism-toolbar.min.css" integrity="sha512-Dqf5696xtofgH089BgZJo2lSWTvev4GFo+gA2o4GullFY65rzQVQLQVlzLvYwTo0Bb2Gpb6IqwxYWtoMonfdhQ==" crossorigin="anonymous" referrerpolicy="no-referrer" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/plugins/line-numbers/prism-line-numbers.min.css" integrity="sha512-cbQXwDFK7lj2Fqfkuxbo5iD1dSbLlJGXGpfTDqbggqjHJeyzx88I3rfwjS38WJag/ihH7lzuGlGHpDBymLirZQ==" crossorigin="anonymous" referrerpolicy="no-referrer" />
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
				<header id="header">
					<a href="index.html" class="logo">Home</a>
				</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li><a href="index.html">About me</a></li>
							<li  class="active"><a href="engineer-projects-4.html">Data Engineer Projects</a></li>
                            <li><a href="analytics-projects-1.html">Data Analytics Projects</a></li>
						</ul>
						<ul class="icons">
							<li><a href="https://www.linkedin.com/in/paul-hankins-075119204/" class="icon brands fa-linkedin"><span class="label">Linkedin</span></a></li>
							<li><a href="https://github.com/Piblo99" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Post -->
							<section class="post">
                                <header class="major">
                                    <h1>Snowflake Data Engineering<br /></h1>
                                    <p>The objective of this project is to explore concepts of data engineering principles
                                        with snowlake, apache kafka, apache airflow, and AWS.
                                    </p>
                                </header>
                                <h2 style="text-align:center;">Consumption and Billing</h2>
                                <p>
                                    Snowflake can be costly. Thankfully Snowflake consumption can be tracked with some SQL Queries!
                                    <br><br>
                                    <a href="https://github.com/Piblo99/Snowflake---Build---Architect-Data-pipelines-using-AWS/blob/master/Section%202%20Consumption%20%26%20Billing/consumption_tracking.sql">Click here for an example</a> 
                                </p>

                                <h2 style="text-align:center;">Snowflake Objects</h2>
                                <p>
                                    There are several different types of tables in snowflake.
                                </p>
                                <ul>
                                    <li>Permanent Tables are the default type of tables.</li>
                                    <li>Temporary Tables are used for results of ad hoc queries that wouldn't be expected to be needed for a long time. This type of table is deleted when a session ends.</li>
                                    <li>Transient Tables are similar to Permanent tables. This type of table exists until they are explicitly dropped. Used to persist transitory data that is needed beyond a session.</li>
                                </ul>
                                <p>
                                    Temporary and transient tables do not have fale-safe and time-travel features enabled.
                                    <br><br>
                                    <a href="https://github.com/Piblo99/Snowflake---Build---Architect-Data-pipelines-using-AWS/blob/master/Section%203%20Different%20Type%20of%20Tables/table_types.sql"> Click here to see an exploration of table types</a>
                                </p>

                                <br>

                                <p>
                                    As for views in snowflake there are Materialized views and non-materialized views.
                                    <br>
                                    The characteristics of materialized views are as follows:
                                </p>
                                <ul>
                                    <li>A materialized view is a per-computed data set derived from a query specification (The select in the view definition) and stored for later use.</li>
                                    <li>Because the data is pre-computed, querying a materialized view is faster than executing a query against the base table of the view</li>
                                    <li>Materialized views can speed up expensive aggregation, projection, and selection operations, especially those that run frequently and those that run on large datasets.</li>
                                </ul>
                                <p>
                                    Views and snowflake can also be defined as secure or insecure.
                                    <br>
                                    The characteristics view security are as follows:
                                </p>
                                <ul>
                                    <li>Views should be defined as secure when they are specifically designated for data privacy.</li>
                                    <li>With secure views, the view definition and details are only visible to authorized users</li>
                                    <li>Both materialized and non-materialized views can be defined as secure</li>
                                    <li>A Secure View has improved data privacy and data sharing.</li>
                                    <li>Both views and materialized views can be clustered for better performance.</li>
                                </ul>
                                <p>
                                    <br><br>
                                    <a href="https://github.com/Piblo99/Snowflake---Build---Architect-Data-pipelines-using-AWS/blob/master/Section%203%20Different%20Type%20of%20Tables/views-materialized_views.sql">Click here for an example of the creation and securing of views.</a>
                                    <a href="https://github.com/Piblo99/Snowflake---Build---Architect-Data-pipelines-using-AWS/blob/master/Section%203%20Different%20Type%20of%20Tables/create-role-to-test-security.sql">Click here for an example of using roles to grant permissions to use secure views.</a>
                                </p>
                                <h2 style="text-align:center;">Partitioning, Clustering, and Performance Optimization</h2>
                                <p>
                                    In snowflake the data inside the table automatically gets divided into smaller chunks of data 
                                    in the range of 50MB to 500MB each called micro-partitions. These micro partitions do not need to be defined 
                                    explicitly & can overlap in the range of values.
                                    The metadata for each of these partitions is stored in the cloud services layer.
                                    <br>
                                    The metadata contains:
                                    <ul>
                                        <li>
                                            Range of values for each of the columns in micro-partitions
                                        </li>
                                        <li>
                                            Number of unique values
                                        </li>
                                        <li>
                                            Additional properties required for efficient query processing and data scanning
                                        </li>       
                                    </ul>

                                    Clustering is characterized by:
                                    <ul>
                                        <li>
                                            Clustering is a process to optimize data retrieval.
                                        </li>
                                        <li>
                                            Clustering is performed on micro-partitions to ensure similar data reside in the same micro-partition which can be fetched in a single query.
                                        </li>
                                        <li>
                                            The Clustering Key is a column or a group of columns that are designated to locate the data in the same micro-partition.
                                        </li>
                                        <li>
                                            Clustering keys play a key role in ensuring the data is sorted/ordered inside the micro-partitions which especially helps while querying large tables.
                                        </li>
                                        <li>
                                            Pruning is a process where snowflake avoids scanning the unnecessary micro-partitions using the clustering keys in the "where clause" thus resulting in better performance.
                                        </li>
                                        <li>
                                            Snowflake automaticalls splits the table into clustered micro-partitions using the natural dimensions such as date columns.
                                        </li>
                                        <li>
                                            These clustered micro-partitions might not be necessarily ideal in the long run. (This is due to the high cardinality associated with these columns.)
                                        </li>
                                    </ul>
                                    <br>
                                    <p>
                                        Considerations for clustering a table in snowflake:
                                    </p>
                                    <ul>
                                        <li>
                                            Table is huge in size. Ideally multiple TBs of data.
                                        </li>
                                        <li>
                                            Majority of the queries are selective (use a where condition on a column or group of columns)
                                        </li>
                                        <li>
                                            Majority of the queries sort the data (use a order by clause)
                                        </li>
                                        <li>
                                            The ratio of queries (reading) and the DML operations should be high.
                                        </li>
                                        <li>
                                            If you want to cluster a large table with a lot of frequent DML operations, consider grouping the DML operations together and running them less frequently.
                                        </li>
                                        <li>
                                            A high number of queries in your entire workload can possibly use the same clustering key.
                                        </li>
                                        <li>
                                            For Example: 95% of the queries in your data ecosystem filter the data and order by using the same set of columns.
                                        </li>
                                    </ul>

                                    <br>
                                    <p> Selecting the clustering keys</p>

                                    <ul>
                                        <li>
                                            A clustering key can be one column or multiple columns. Ideally the max number of columns should be limited to 3.
                                        </li>
                                        <li>
                                            Columns with low and high cardinality are not good candidates for clustering keys and must be avoided.
                                        </li>
                                        <li>
                                            Eg: If you select a timestamp value (high cardinality) or a gender column with extremely low cardinality, this will result in poor performance of your queries and high clustering costs will be incurred.
                                        </li>
                                        <li>
                                            If the clustering key is multiple columns, the order in which the columns are specified in the create table or alter table statement is important. As a rule of thumb, columns must be specified from low to high cardinality.
                                        </li>
                                    </ul>
                                    <br><br>
                                    <a href="https://github.com/Piblo99/Snowflake---Build---Architect-Data-pipelines-using-AWS/blob/master/Section%204%20Micropartitions%20%26%20Clustering/selecting_clustering_keys.sql">Click here to see an example of selecting clustering keys</a>
                                    <br>
                                    Snowflake allows you to check the query history and even filter by the types of queries executed. This helps with monitoring for performance checking and security purposes.
                                    <br><br>
                                    <a href="https://github.com/Piblo99/Snowflake---Build---Architect-Data-pipelines-using-AWS/blob/master/Section%204%20Micropartitions%20%26%20Clustering/query_history.sql">Click here to see an example of query history checking</a>
                                    <br>
                                    Snowflake allows you to leverage a feature called search optimiation when using point lookup queries.
                                    Point lookup queries are queries in which the where clause is used to select rows for a particular column.
                                    Eg: Select * from table where column = "abc"

                                    <br><br>
                                    <a href="https://github.com/Piblo99/Snowflake---Build---Architect-Data-pipelines-using-AWS/blob/master/Section%204%20Micropartitions%20%26%20Clustering/search_optimization.sql">Click here to see an example Snowflake's search optimization</a>
                                </p>
                                <h2 style="text-align:center;">Data Loading/Ingestion and Extraction</h2>
                                <p>

                                </p>

                                <h2 style="text-align:center;">Tasks and Query Scheduling</h2>
                                <p>

                                </p>
                                <h2 style="text-align:center;">Streams and Change Data Capture</h2>
                                <p>

                                </p>

                                <h2 style="text-align:center;">User Defined Functions</h2>
                                <p>

                                </p>
                                <h2 style="text-align:center;">External Functions</h2>
                                <p>

                                </p>

                                <h2 style="text-align:center;">Snowflake with Python Spark and Airflow on AWS</h2>
                                <p>

                                </p>
                                <h2 style="text-align:center;">Realtime Streaming with Kafka and Snowflake</h2>
                                <p>

                                </p>

                                <h2 style="text-align:center;">Data Protection and Governance</h2>
                                <p>

                                </p>
							</section>

					</div>

				<!-- Footer -->
                <footer id="footer">
                    <section class="alt">
                        <h3>Address</h3>
                        <p>BARTLESVILLE, OK</p>
                    </section>
                    <section>
                        <h3>Phone</h3>
                        <p>(504) 201-4748</p>
                    </section>
                    <section>
                        <h3>Email</h3>
                        <p>paulhankins99@gmail.com</p>
                    </section>
                    <section>
                        <h3>Social</h3>
                        <ul class="icons alt">
                            <li><a href="https://www.linkedin.com/in/paul-hankins-075119204/" class="icon brands alt fa-linkedin"><span class="label">Linkedin</span></a></li>
                            <li><a href="https://github.com/Piblo99" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>
                        </ul>
                    </section>
            </footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>
            <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/prism.min.js"></script>
            <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/plugins/toolbar/prism-toolbar.min.js" integrity="sha512-st608h+ZqzliahyzEpETxzU0f7z7a9acN6AFvYmHvpFhmcFuKT8a22TT5TpKpjDa3pt3Wv7Z3SdQBCBdDPhyWA==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
            <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/plugins/copy-to-clipboard/prism-copy-to-clipboard.min.js" integrity="sha512-/kVH1uXuObC0iYgxxCKY41JdWOkKOxorFVmip+YVifKsJ4Au/87EisD1wty7vxN2kAhnWh6Yc8o/dSAXj6Oz7A==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
            <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/plugins/line-numbers/prism-line-numbers.min.js" integrity="sha512-BttltKXFyWnGZQcRWj6osIg7lbizJchuAMotOkdLxHxwt/Hyo+cl47bZU0QADg+Qt5DJwni3SbYGXeGMB5cBcw==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
            <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/components/prism-python.min.js" integrity="sha512-AKaNmg8COK0zEbjTdMHJAPJ0z6VeNqvRvH4/d5M4sHJbQQUToMBtodq4HaV4fa+WV2UTfoperElm66c9/8cKmQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
	</body>
</html>