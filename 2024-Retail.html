<!DOCTYPE HTML>
<html>
	<head>
		<title>Paul Hankins</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/themes/prism-dark.min.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/plugins/toolbar/prism-toolbar.min.css" integrity="sha512-Dqf5696xtofgH089BgZJo2lSWTvev4GFo+gA2o4GullFY65rzQVQLQVlzLvYwTo0Bb2Gpb6IqwxYWtoMonfdhQ==" crossorigin="anonymous" referrerpolicy="no-referrer" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/plugins/line-numbers/prism-line-numbers.min.css" integrity="sha512-cbQXwDFK7lj2Fqfkuxbo5iD1dSbLlJGXGpfTDqbggqjHJeyzx88I3rfwjS38WJag/ihH7lzuGlGHpDBymLirZQ==" crossorigin="anonymous" referrerpolicy="no-referrer" />
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
				<header id="header">
					<a href="index.html" class="logo">Home</a>
				</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li><a href="index.html">About me</a></li>
                            <li  class="active"><a href="2024-engineer-projects.html">Engineer Projects 2024</a></li>
							<li  class=""><a href="engineer-projects-2.html">Engineer Projects 2022</a></li>
                            <li><a href="analytics-projects-1.html">Analytics Projects 2022</a></li>
						</ul>
						<ul class="icons">
							<li><a href="https://www.linkedin.com/in/paul-hankins-075119204/" class="icon brands fa-linkedin"><span class="label">Linkedin</span></a></li>
							<li><a href="https://github.com/Piblo99" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
						</ul>
					</nav>
                    
                    <style>
                        img {
                            max-width: 1000px;
                            width: 100%;
                            height: auto;
                        }


                        .main.special {
                            padding-bottom: 100px;
                        }

                    </style>
				<!-- Main -->
					<div id="main">

						<!-- Post -->
							<section class="post">
                                <header class="major">
                                    <h1>Retail Sales Data Warehouse Project</h1>
                                    

                                    <!-- Project Scope Section -->
                                    <section id="project-scope" class="main special">
                                        <header class="major">
                                            <h3>Identify Project Scope</h3>
                                        </header>
                                        <p>The scope of this retail data warehouse project includes the design, development, and implementation of a data warehousing solution tailored for the retail industry using the Northwind database. It covers the following areas:</p>
                                        <ul style="text-align:left;">
                                            <li>Defining the data sources and data sets to be included.</li>
                                            <li>Establishing the data integration and transformation requirements.</li>
                                            <li>Designing the data model to support business intelligence and reporting.</li>
                                            <li>Creating a scalable infrastructure for data storage and retrieval.</li>
                                            <li>Ensuring data quality and governance throughout the project lifecycle.</li>
                                            <li>Setting up the project's technical and business constraints, timelines, and deliverables.</li>
                                        </ul>
                                        <p>The project aims to enable better decision-making through enhanced data insights and analytics, providing a comprehensive view of the retail sales operations.</p>
                                    </section>
                                    
                                    <!-- Project Planning Section -->
                                    <section id="project-planning" class="main special">
                                        <header class="major">
                                            <h3>Project Planning</h3>
                                        </header>
                                        <p>To ensure the success of the Retail Sales Data Warehouse project, a strategic plan has been developed. This plan will guide the project from inception through to completion:</p>
                                        <ol style="text-align:left;">
                                            <li>Defining the detailed scope of the data warehouse requirements.</li>
                                            <li>Setting clear, measurable goals and objectives aligned with retail business strategies.</li>
                                            <li>Outlining the implementation strategy including the methodologies and technologies to be used.</li>
                                            <li>Identifying the necessary resources, including team members, hardware, and software tools.</li>
                                            <li>Creating a detailed project timeline with milestones and deliverables for each phase of the project.</li>
                                        </ol>
                                        <p>This project planning stage is crucial for aligning expectations, setting clear directions, and laying the foundation for the subsequent steps in the data warehouse development process.</p>
                                    </section>
                                    
                                    <!-- Requirements Gathering Section -->
                                    <section id="requirements-gathering" class="main special">
                                        <header class="major">
                                            <h3>Gather Requirements/Requirements Definition</h3>
                                        </header>
                                        <p>A critical step in designing a data warehouse is to understand the business needs and data requirements. This process includes:</p>
                                        <ul style="text-align:left;">
                                            <li>Conducting user interviews to capture user stories and expectations.</li>
                                            <li>Reviewing and digesting existing reports and artifacts to ensure continuity and improvement.</li>
                                            <li>Determining the inputs and data sources as well as identifying who will provide them.</li>
                                            <li>Assigning responsibility among team members for different aspects of requirement gathering.</li>
                                            <li>Performing thorough interviews and discussions to refine and document requirements.</li>
                                            <li>Analyzing existing data sources for quality, structure, and integration feasibility.</li>
                                        </ul>
                                        <p>This foundational stage sets the stage for a data warehouse that is closely aligned with business objectives and user needs.</p>

                                        <!-- Requirements Gathering - Interview Questions -->
                                        <section id="requirements-interview-questions" class="main">
                                            <header class="major">
                                                <h4>Common Interview Questions During Requirements Gathering</h4>
                                            </header>
                                            <p>Engaging with stakeholders through interviews is a pivotal part of the requirements gathering process. Here is a selection of common questions that help in uncovering the necessary details for a successful data warehouse project:</p>
                                            <ul style="text-align:left;">
                                                <li>What is the primary purpose or objective of this data warehouse implementation?</li>
                                                <li>What issues is the business currently facing in daily operations?</li>
                                                <li>Are there any regulatory or compliance requirements driving this project?</li>
                                                <li>What temporary measures or workarounds are currently in place?</li>
                                                <li>What improvements or benefits does the business expect from this implementation?</li>
                                                <li>What are the risks if the project is not completed on time, and how critical are these timelines?</li>
                                                <li>What data is currently available, and what challenges are associated with it?</li>
                                                <li>What are the short-term and long-term deliverables and goals for this project?</li>
                                                <li>How does the business benefit from the data warehouse both immediately and in the future?</li>
                                            </ul>
                                            <p>These questions are tailored to initiate detailed conversations that inform the design and implementation strategy, leading to a solution that truly aligns with business goals and operational requirements.</p>
                                        </section>

                                    </section>

                                    <!-- Data Profiling Section -->
                                    <section id="data-profiling" class="main special">
                                        <header class="major">
                                            <h3>Data Profiling</h3>
                                        </header>
                                        <p>As an essential part of the requirements gathering, data profiling is carried out to ensure the quality and structure of the data are well understood. This step involves:</p>
                                        <ul style="text-align:left;">
                                            <li>Analyzing the existing data to identify patterns, anomalies, or inconsistencies.</li>
                                            <li>Evaluating the data for completeness, accuracy, and reliability.</li>
                                            <li>Understanding data distribution, key relationships, and dependencies.</li>
                                            <li>Ensuring data governance and compliance with regulatory requirements.</li>
                                        </ul>
                                        <p>Data profiling results are crucial for defining transformation rules, cleaning strategies, and ultimately for the logical and physical design of the data warehouse.</p>
                                    </section>

                                    <!-- OLTP Tables Overview -->
                                    <section id="oltp-tables-overview" class="main special">
                                        <header class="major">
                                            <h4>OLTP Tables Overview</h4>
                                        </header>
                                        <p>Following our data profiling activities, we've pinpointed essential OLTP tables that are instrumental for constructing our dimensional data warehouse. These tables will provide a granular view of the business processes and are vital for a comprehensive analysis:</p>
                                        <ul style="text-align:left;">
                                            <li><strong>Customers</strong> - Records purchases made by customers from Northwind.</li>
                                            <li><strong>Employees</strong> - Details on employees; understanding both customer and employee roles is crucial.</li>
                                            <li><strong>Orders</strong> - Captures all sales order transactions between customers and Northwind.</li>
                                            <li><strong>Order Details</strong> - Contains specifics for each order placed by customers.</li>
                                            <li><strong>Inventory Transaction</strong> - Holds transaction details for inventory movement.</li>
                                            <li><strong>Products</strong> - Includes all product information to analyze sales performance.</li>
                                            <li><strong>Shippers</strong> - Details on how orders are shipped from Northwind to customers.</li>
                                            <li><strong>Suppliers</strong> - Information on suppliers providing goods to Northwind.</li>
                                            <li><strong>Invoices</strong> - Invoice data created for each order.</li>
                                        </ul>
                                        <p>This selection process is exploratory and somewhat conjectural, requiring an iterative approach with constant validation and refinement in collaboration with business stakeholders. The goal is to ensure that each chosen table aligns perfectly with the intended business processes and analytics requirements.</p>
                                    </section>

                                    <!-- OLTP System ER Diagram -->
                                    <section id="oltp-er-diagram" class="main special">
                                        <header class="major">
                                            <h4>OLTP System ER Diagram</h4>
                                        </header>
                                        <p>Before we proceed to the conceptual design of our data warehouse, it's essential to understand the relationships and structure of our current OLTP system. Below is the ER diagram representing the Northwind database's schema:</p>
                                        <figure>
                                            <img style="max-width:1000px;" src="images/retail-ssis/Northwind_Physical_ER.png" alt="OLTP System ER Diagram">
                                            <figcaption>An Entity-Relationship Diagram of the Northwind OLTP System.</figcaption>
                                        </figure>
                                        <p>This diagram will serve as a foundation for identifying which entities will translate into dimensions and facts in our data warehouse, ensuring we retain the integrity and context of the data during transformation.</p>
                                    </section>


                                    <!-- Data Profiling with SSIS Section -->
                                    <section id="data-profiling-ssis" class="main special">
                                        <header class="major">
                                            <h4>Data Profiling with SSIS</h4>
                                        </header>
                                        <p>Data profiling is a vital step in understanding the quality and structure of the data we plan to use in our data warehouse. While there are various methods to perform data profiling, including manual analysis with SQL or Python, SQL Server Integration Services (SSIS) offers a built-in Data Profiling task that simplifies this process.</p>
                                        <p>In our Northwind database project, we utilized SSIS's profiling task to examine each table comprehensively.</p>
                                        <p style="text-align:center;"><i>Note that one table's profiles are shown for brevity.</i><br>Here's what we looked into:</p>
                                        
                                        <figure>
                                            <img src="images/retail-ssis/Candidate_Profile.png" alt="Candidate Key Profiles">
                                            <figcaption>Candidate Key Profiles: Identifying unique records within tables.</figcaption>
                                        </figure>

                                        <figure>
                                            <img src="images/retail-ssis/Length_Profile.png" alt="Column Length Distribution Profiles">
                                            <figcaption>Column Length Distribution Profiles: Analyzing the variation in data size across records.</figcaption>
                                        </figure>

                                        <figure>
                                            <img src="images/retail-ssis/Null_Profile.png" alt="Column Null Ratio Profiles">
                                            <figcaption>Column Null Ratio Profiles: Assessing the frequency of null values in each column.</figcaption>
                                        </figure>

                                        <figure>
                                            <img src="images/retail-ssis/Pattern_Profile.png" alt="Column Pattern Profiles">
                                            <figcaption>Column Pattern Profiles: Identifying common patterns within textual data.</figcaption>
                                        </figure>

                                        <figure>
                                            <img src="images/retail-ssis/Stats_Profile.png" alt="Column Statistics Profiles">
                                            <figcaption>Column Statistics Profiles: Gathering statistics such as min, max, and average values.</figcaption>
                                        </figure>

                                        <figure>
                                            <img src="images/retail-ssis/Value_Profile.png" alt="Column Value Distribution Profiles">
                                            <figcaption>Column Value Distribution Profiles: Understanding the distribution of data within columns.</figcaption>
                                        </figure>

                                        <figure>
                                            <img src="images/retail-ssis/Dependency_Profile.png" alt="Functional Dependency Profiles">
                                            <figcaption>Functional Dependency Profiles: Analyzing the dependencies between different columns.</figcaption>
                                        </figure>
                                        
                                        <br>
                                        <p>To summarize, through SSIS data profiling, we scrutinized aspects such as the uniqueness of data, column length distributions, presence of nulls, patterns in text data, statistical measures, distribution of values, and column dependencies. This analysis ensures that the data imported into our data warehouse is of high quality and integrity, setting a strong foundation for reliable analytics and business intelligence.</p>
                                    </section>
                                    
                                    <!-- Dimensional Modeling Section -->
                                    <section id="dimensional-modeling" class="main special">
                                        <header class="major">
                                            <h4>Dimensional Modeling</h4>
                                        </header>
                                        <p>Dimensional modeling is a design technique used for organizing data into structures optimized for business intelligence and data analytics. It focuses on making data easy to understand and query by emphasizing the business's key metrics and data relationships.</p>
                                        <p>Unlike transactional models used in OLTP systems, dimensional modeling is optimized for read-heavy queries and often organizes data into star or snowflake schemas. This makes it particularly suitable for data warehouses.</p>
                                        <p>The following steps outline the dimensional modeling approach:</p>
                                        <ul style="text-align:left;">
                                            <li><strong>Select the Business Process</strong>: Identify the core business process or event that needs to be analyzed (e.g., sales transactions).</li>
                                            <li><strong>Declare the Grain</strong>: Define the granularity of the data, or what a single row in the fact table represents (e.g., one order, one transaction line item).</li>
                                            <li><strong>Identify the Dimensions</strong>: Determine the dimensions that provide context for the facts, such as time, product, customer, and location.</li>
                                            <li><strong>Identify the Facts</strong>: Establish the key metrics or measures for the fact table, like sales revenue or order quantity.</li>
                                            <li><strong>Design the Schema</strong>: Organize the dimensions and facts into star or snowflake schemas based on the business requirements.</li>
                                        </ul>
                                        <p>In the following subsections, we'll elaborate on the conceptual, logical, and physical models used in designing a dimensional data warehouse.</p>
                                    </section>

                                    <!-- Bus Matrix Section -->
                                    <section id="bus-matrix" class="main special">
                                        <header class="major">
                                            <h4>Bus Matrix</h4>
                                        </header>
                                        <p>The bus matrix is a critical component in planning and designing a dimensional data warehouse. Introduced by Ralph Kimball, it serves multiple purposes in aligning the data warehouse with business objectives:</p>
                                        <ul style="text-align:left;">
                                            <li><strong>Presentation of Data Marts:</strong> The bus matrix provides the first level of visualization for data marts and the relationships between dimensions and fact tables.</li>
                                            <li><strong>Objective Explanation:</strong> It communicates the data warehouse's overall objective to both technical and business stakeholders.</li>
                                            <li><strong>Technical and Management Document:</strong> Acts as a reference for both technical teams and executives, ensuring alignment across levels.</li>
                                            <li><strong>Mapping Business Processes to Dimensions:</strong> It shows the mapping between business processes (fact tables) and dimensions before development begins.</li>
                                        </ul>
                                        <p>To approach the creation of a bus matrix:</p>
                                        <ul style="text-align:left;">
                                            <li><strong>Identify Business Processes</strong>: Determine the primary business processes (fact tables) that will be analyzed and supported by the data warehouse.</li>
                                            <li><strong>List Dimensions</strong>: Define the confirmed dimensions that will provide context to the fact tables (e.g., time, customer, product, etc.).</li>
                                            <li><strong>Map Relationships</strong>: Identify the relationships between fact tables and the dimensions to show how different business processes will share the same dimensional data.</li>
                                            <li><strong>Prioritize Business Processes</strong>: Prioritize each business process based on its complexity and value to the organization, ensuring high-priority processes are addressed first.</li>
                                        </ul>
                                        <p>Below is a bus matrix for the Northwind Retail Sales Data Warehouse Project. It outlines the relationship between various business processes and dimensions:</p>
                                        <figure>
                                            <img src="images/retail-ssis/Northwind_Bus_Matrix.png" alt="Bus Matrix for Northwind Retail Sales Data Warehouse">
                                            <figcaption>Bus Matrix for Northwind Retail Sales Data Warehouse Project</figcaption>
                                        </figure>
                                        <p>The business processes included in this bus matrix are:</p>
                                        <ul style="text-align:left;">
                                            <li><strong>Sales Overview</strong>: Provides an overall view of all transactions, allowing for comprehensive sales analysis.</li>
                                            <li><strong>Sales Agent</strong>: Tracks the performance of sales agents and identifies their impact on overall sales.</li>
                                            <li><strong>Product Inventory</strong>: Offers detailed insight into inventory transactions, enabling effective inventory management.</li>
                                            <li><strong>Customer Reporting</strong>: Enables analysis of customer data to refine strategies for better customer satisfaction and engagement.</li>
                                        </ul>
                                        <p>This bus matrix helps prioritize development tasks and establish a clear roadmap for the project's implementation, guiding both technical and business stakeholders toward a cohesive vision.</p>
                                    </section>

                                    <!-- Conceptual Model Section -->
                                    <section id="conceptual-model" class="main special">
                                        <header class="major">
                                            <h4>Conceptual Model</h4>
                                        </header>
                                        <p>The conceptual model provides a high-level visual representation of the data warehouse. It serves several purposes in the design phase:</p>
                                        <ul style="text-align:left;">
                                            <li><strong>Defines High-Level Entities:</strong> It identifies the key business entities that the data warehouse will represent.</li>
                                            <li><strong>Clarifies Relationships:</strong> It outlines the relationships between various entities without getting into specific attributes or database constraints.</li>
                                            <li><strong>Facilitates Stakeholder Communication:</strong> It helps business and technical stakeholders reach a common understanding of the data warehouse architecture.</li>
                                        </ul>
                                        <p>The approach to creating a conceptual model involves:</p>
                                        <ul style="text-align:left;">
                                            <li>Identifying the core business entities (e.g., Customers, Sales Orders, Products).</li>
                                            <li>Understanding the high-level relationships between these entities.</li>
                                            <li>Representing each entity and relationship visually in a clear and straightforward manner.</li>
                                        </ul>
                                        <p>The diagram below illustrates the conceptual model for the Northwind Retail Sales Data Warehouse:</p>
                                        <figure>
                                            <img src="images/retail-ssis/Conceptual_Model.png" alt="Conceptual Model of Northwind Retail Sales Data Warehouse">
                                            <figcaption>Conceptual Model for the Northwind Retail Sales Data Warehouse Project</figcaption>
                                        </figure>
                                        <p>This model will serve as a blueprint for the logical and physical models that will be developed in the following phases.</p>
                                    </section>

                                    <!-- Source to Target Mapping: OLTP to Staging -->
                                    <section id="source-to-target-mapping-oltp-staging" class="main special">
                                        <header class="major">
                                            <h4>Source to Target Mapping: OLTP to Staging</h4>
                                        </header>
                                        <p>This section describes the planning and mapping of data flows from the OLTP system to the staging area using Excel for meticulous mapping documentation. This preparatory step ensures that all transformations and data requirements are clearly defined before any actual data movement occurs.</p>
                                        <ul style="text-align:left;">
                                            <li><strong>Mapping Documentation:</strong> Utilizing Excel spreadsheets to meticulously document how data is extracted and what transformations are necessary.</li>
                                            <li><strong>Transformation Rules:</strong> Defining clear transformation rules in the mapping sheets to ensure consistency and accuracy during the staging phase.</li>
                                            <li><strong>Data Flow Planning:</strong> Planning the data flows to optimize extraction and staging operations.</li>
                                            <li><strong>Review and Validation:</strong> Ensuring that all mappings are reviewed and validated for completeness and correctness before implementation.</li>
                                        </ul>
                                        <!-- OLTP System Diagram Placeholder -->
                                        <figure>
                                            <img src="images/retail-ssis/oltp_source_map.png" alt="OLTP System Diagram">
                                            <figcaption>Source System - SQL Server OLTP Database</figcaption>
                                        </figure>
                                        <!-- Staging Area Diagram Placeholder -->
                                        <figure>
                                            <img src="images/retail-ssis/staging_target_map.png" alt="Staging Area Diagram">
                                            <figcaption>Target System - SQL Server Staging Area</figcaption>
                                        </figure>
                                        <p>Excel spreadsheets serve as a crucial tool in ensuring all data handling steps are carefully planned and documented.</p>
                                    </section>

                                    <!-- Source to Target Mapping: Staging to Data Warehouse -->
                                    <section id="source-to-target-mapping-staging-warehouse" class="main special">
                                        <header class="major">
                                            <h4>Source to Target Mapping: Staging to Data Warehouse</h4>
                                        </header>
                                        <p>This section focuses on the mapping of data from the staging area to the data warehouse, detailing the specific mapping plans created in Excel. These plans are crucial for ensuring data is accurately organized and integrated into the warehouse.</p>
                                        <ul style="text-align:left;">
                                            <li><strong>Data Integration Planning:</strong> Mapping out how data will be integrated from the staging area to different tables in the warehouse.</li>
                                            <li><strong>Dimensional Mapping:</strong> Detailed planning of how each piece of data fits into the warehouse's dimensional schema.</li>
                                            <li><strong>Optimization Strategies:</strong> Strategies to optimize the data load into the warehouse for efficient querying and storage.</li>
                                            <li><strong>Validation:</strong> Ensuring the mapping aligns with business needs and warehouse design principles.</li>
                                        </ul>
                                        <!-- Staging Area Diagram Placeholder -->
                                        <figure>
                                            <img src="images/retail-ssis/staging_source_map.png" alt="Staging Area Diagram">
                                            <figcaption>Source System - SQL Server Staging Area</figcaption>
                                        </figure>
                                        <!-- Data Warehouse Diagram Placeholder -->
                                        <figure>
                                            <img src="images/retail-ssis/warehouse_target_map.png" alt="Data Warehouse Diagram">
                                            <figcaption>Target System - SQL Server Data Warehouse</figcaption>
                                        </figure>
                                        <p>The detailed mapping in Excel underpins the successful transformation and integration of staging data into the warehouse structure.</p>
                                    </section>

                                    <!-- Logical Design Section -->
                                    <section id="logical-design" class="main special">
                                        <header class="major">
                                            <h4>Logical Design</h4>
                                        </header>
                                        <p>The logical design of the data warehouse involves defining the structure and relationships between different entities (fact and dimension tables) without considering the physical implementation details. It provides a blueprint for organizing and structuring data based on business needs.</p>
                                        <ul style="text-align:left;">
                                            <li><strong>Data Organization:</strong> Identifies the main business processes to model and determines how the data will be organized into facts and dimensions.</li>
                                            <li><strong>Schema Design:</strong> Specifies the star or snowflake schema, listing the fact and dimension tables and their relationships.</li>
                                            <li><strong>Data Granularity:</strong> Defines the level of detail (grain) to capture in the fact tables, such as transactional vs. aggregated data.</li>
                                            <li><strong>Key Structures:</strong> Maps primary and foreign keys to maintain referential integrity between facts and dimensions.</li>
                                        </ul>
                                        <p>Approach to Logical Design:</p>
                                        <ul style="text-align:left;">
                                            <li><strong>Gather Business Requirements:</strong> Identify key business processes and metrics to analyze in the data warehouse.</li>
                                            <li><strong>Model Facts and Dimensions:</strong> Design fact and dimension tables, ensuring data is organized consistently with business needs.</li>
                                            <li><strong>Define Relationships:</strong> Establish relationships between facts and dimensions, maintaining a cohesive structure.</li>
                                            <li><strong>Review Design:</strong> Validate the design with stakeholders to ensure that all reporting requirements are met.</li>
                                        </ul>

                                        <!-- Logical Model Diagram Placeholder -->
                                        <figure>
                                            <img src="images/retail-ssis/Logical_model.png" alt="Logical Model Diagram">
                                            <figcaption>Logical Model Diagram</figcaption>
                                        </figure>

                                        <p>The logical design step provides a comprehensive structure for the data warehouse, ensuring that all business processes are accurately represented and analyzed.</p>
                                    </section>


                                    <!-- Physical Design Section -->
                                    <section id="physical-design" class="main special">
                                        <header class="major">
                                            <h4>Physical Design</h4>
                                        </header>
                                        <p>The physical design of the data warehouse translates the logical design into a technical specification for database implementation. It involves the physical arrangement of data across storage media to optimize query performance and achieve scalability and maintenance goals.</p>
                                        <ul style="text-align:left;">
                                            <li><strong>Table Structures:</strong> Defines physical tables based on logical entities, including appropriate storage settings and partitioning schemes.</li>
                                            <li><strong>Indexing:</strong> Implements indexes to improve query performance and speed up access to frequently queried columns.</li>
                                            <li><strong>Data Partitioning:</strong> Applies partitioning strategies to divide large tables into manageable parts, improving maintenance and data access performance.</li>
                                            <li><strong>Physical Optimization:</strong> Includes the implementation of physical database design techniques like the proper alignment of disks and memory optimization to ensure efficient data retrieval.</li>
                                        </ul>
                                        <p>Approach to Physical Design:</p>
                                        <ul style="text-align:left;">
                                            <li><strong>Optimize for Performance:</strong> Optimize database structures for the specific queries and loads they will support, which may involve denormalization and aggregation strategies.</li>
                                            <li><strong>Consider Hardware Resources:</strong> Design the physical model taking into account available hardware resources to maximize performance within system constraints.</li>
                                            <li><strong>Ensure Scalability:</strong> Design the database to handle increases in data volume without significant performance degradation.</li>
                                            <li><strong>Review and Testing:</strong> Test the physical design under realistic load scenarios to ensure that it meets the required performance criteria.</li>
                                        </ul>

                                        <!-- Physical Model Diagram Placeholder -->
                                        <figure>
                                            <img src="images/retail-ssis/Physical_Model.png" alt="Physical Model Diagram">
                                            <figcaption>Physical Model Diagram for the Northwind Retail Sales Data Warehouse</figcaption>
                                        </figure>

                                        <p>This physical design step ensures the data warehouse is built on a robust architecture that supports efficient data processing and retrieval, facilitating effective data analysis.</p>
                                    </section>

                                    <!-- Physical Implementation of Staging Layer -->
                                    <section id="physical-implementation-staging" class="main special">
                                        <header class="major">
                                            <h4>Physical Implementation of the Staging Layer</h4>
                                        </header>
                                        <p>The staging layer plays a crucial role in the data warehousing process, serving as an intermediary area where data from various source systems is consolidated, cleansed, and prepared before being loaded into the data warehouse. This layer allows for the handling of data in a controlled environment where transformations and quality checks can be performed without impacting the performance of the source systems.</p>
                                        <ul style="text-align:left;">
                                            <li><strong>Data Consolidation:</strong> Data from different source systems is consolidated into the staging area. This process involves extracting data from each source, which can vary widely in format and structure.</li>
                                            <li><strong>Cleansing and Preparation:</strong> Once in the staging area, data can be cleaned, transformed, and restructured to meet the requirements of the target data warehouse schema. This includes standardizing data formats, correcting anomalies, and resolving data quality issues.</li>
                                            <li><strong>Temporal Data Management:</strong> The staging area often handles temporal data management by adding timestamps, which helps in tracking data changes over time.</li>
                                        </ul>
                                        <p>For the Northwind Retail Sales Data Warehouse Project, the following steps were implemented in the staging layer using SQL Server Integration Services (SSIS):</p>
                                        <ul style="text-align:left;">
                                            <li><strong>Data Transfer:</strong> Data was transferred from the SQL Server OLTP system to the staging area, ensuring that the integrity and consistency of the data were maintained during the transfer.</li>
                                            <li><strong>Schema Alteration:</strong> After the data transfer, the schema of the imported tables was changed from dbo to stg to clearly differentiate staging data from operational data and to organize the data better for further processing.</li>
                                            <li><strong>Ingestion Timestamp Addition:</strong> An ingestion timestamp column was added to each table to record the exact time data was moved into the staging area, which is crucial for tracking data lineage and refresh schedules.</li>
                                        </ul>
                                        <p>This structured approach ensures that the data is appropriately prepared for loading into the data warehouse, supporting efficient data management and high-quality data analytics.</p>
                                        <figure>
                                            <img src="images/retail-ssis/Retail_SSIS_Staging.png" alt="SSIS Package Diagram for Staging">
                                            <figcaption>SSIS Package Implementation for the Staging Layer</figcaption>
                                        </figure>
                                    </section>

                                    <!-- Physical Implementation of Data Warehouse Layer -->
                                    <section id="physical-implementation-data-warehouse" class="main special">
                                        <header class="major">
                                            <h4>Physical Implementation of the Data Warehouse Layer</h4>
                                        </header>
                                        <p>The data warehouse layer is a crucial component of a comprehensive data warehousing solution, designed to facilitate efficient query processing and support complex analytical tasks. This layer typically involves the construction and utilization of structured data storage mechanisms, like dimensional and fact tables, within a data warehouse.</p>
                                        <p>Approaching the creation of a data warehouse layer usually includes:</p>
                                        <ul style="text-align:left;">
                                            <li><strong>Structural Design:</strong> Establishing a schema that optimally supports the specific business intelligence and analytics needs of the organization.</li>
                                            <li><strong>Data Integration:</strong> Integrating and consolidating data from various source systems into the warehouse using transformation rules defined during the staging process.</li>
                                            <li><strong>Indexing and Performance Optimization:</strong> Implementing indexing strategies to enhance data retrieval speeds and optimize query performance.</li>
                                            <li><strong>Testing and Validation:</strong> Rigorously testing the implemented structures for integrity and performance to ensure they meet the expected requirements.</li>
                                        </ul>
                                        <p>This phase is critical for ensuring that the data stored in the warehouse can be accessed quickly and reliably, providing the backbone for all subsequent data retrieval and analysis operations.</p>
                                        <p>In this project, the SSIS package was structured to manage data across several dimensions and fact tables effectively. This included:</p>
                                        <ul style="text-align:left;">
                                            <li><strong>Clear Operations:</strong> Using tasks to clear existing data before loading new data. This includes tasks like 'clear_dim_customer' and 'clear_fact_sales' to ensure data freshness and integrity.</li>
                                            <li><strong>Data Loading:</strong> Implementing data flow tasks to load data into dimension tables like 'dim_customer', 'dim_employee', and 'dim_product', and fact tables like 'fact_sales' and 'fact_inventory', which are crucial for detailed analytics and reporting.</li>
                                            <li><strong>Dependency Management:</strong> Managing dependencies carefully to ensure that data is processed in the correct order, which is essential for maintaining data accuracy across related dimensions and facts.</li>
                                            <li><strong>Creating and Managing Keys:</strong> Creating surrogate keys for dimension and fact tables, and ensuring proper foreign key relationships between tables to maintain referential integrity.</li>
                                            <li><strong>Handling Orphaned Records:</strong> Updating orphaned fact table rows to ensure no orphaned records exist, improving data consistency and reliability.</li>
                                            <li><strong>Adding and Dropping Constraints:</strong> Ensuring constraints are properly managed to maintain data integrity throughout the ETL process, including the conditional addition and removal of primary and foreign key constraints.</li>
                                        </ul>
                                    </section>
                                        <!-- Placeholder for SSIS Diagram -->
                                        <figure>
                                            <img src="images/retail-ssis/physical_warehouse_package.png" alt="SSIS Dimensions and Fact Tables">
                                            <figcaption>Diagram of the SSIS Dimensions and Fact Tables implemented in the Data Warehouse Layer</figcaption>
                                        </figure>
                                    </section>

                                    <!-- Detailed Implementation of Dimension Tables -->
                                    <section id="detailed-implementation-dimensions" class="main special">
                                        <header class="major">
                                            <h4>Detailed Implementation of Dimension Tables</h4>
                                        </header>
                                        <p>This section provides a detailed look at the implementation of specific dimension tables within the data warehouse, showcasing the steps taken to prepare and integrate these dimensions using SQL and SSIS. (Note: only showing the most interesting tables for brevity)</p>
                                        
                                        <!-- Dimension Table: dim_date -->
                                        <section id="dim-date-implementation" class="main special">
                                            <header class="major">
                                                <h5>Dimension Table: dim_date</h5>
                                            </header>
                                            <p>The <code>dim_date</code> table is created to provide a structured time dimension for the data warehouse. A comprehensive date table is essential for performing time-based analysis and supporting reports that aggregate data across different time periods.</p>
                                            <p>The SQL query used to generate this table populates it with a range of dates, each broken down into various components such as year, quarter, month, day, and even fiscal quarters. This allows for versatile time-based querying in the warehouse.</p>
                                            <!-- Placeholder for SQL Query for dim_date -->
                                            <figure>
                                                <img src="images/retail-ssis/dim_date_query.png" alt="SQL Query for dim_date">
                                                <figcaption>SQL Query used to populate the dim_date table</figcaption>
                                            </figure>
                                            <!-- Placeholder for Results of dim_date -->
                                            <figure>
                                                <img src="images/retail-ssis/dim_date_data.png" alt="Data in dim_date">
                                                <figcaption>Sample data from the populated dim_date table</figcaption>
                                            </figure>
                                        </section>
                                        
                                        <!-- Dimension Table: dim_product -->
                                        <section id="dim-product-implementation" class="main special">
                                            <header class="major">
                                                <h5>Dimension Table: dim_product</h5>
                                            </header>
                                            <p>The <code>dim_product</code> table involves more complex data integration steps. It utilizes SSIS to handle data deduplication and merging from multiple sources, ensuring high data quality and consistency. This table is crucial for storing comprehensive product information that supports sales and inventory analysis.</p>
                                            <p>The SSIS data flow diagram below illustrates the process of extracting, transforming, and loading product data. Key steps include deduplication of products and suppliers, converting supplier data types, and merging this data before loading it into the <code>dim_product</code> table.</p>
                                            <!-- Placeholder for SSIS Data Flow for dim_product -->
                                            <figure>
                                                <img src="images/retail-ssis/dim_product_flow.png" alt="SSIS Data Flow for dim_product">
                                                <figcaption>SSIS Data Flow for constructing the dim_product table</figcaption>
                                            </figure>
                                            <!-- Placeholder for Data in dim_product -->
                                            <figure>
                                                <img src="images/retail-ssis/dim_product_data.png" alt="Data in dim_product">
                                                <figcaption>Sample data from the populated dim_product table</figcaption>
                                            </figure>
                                        </section>



                                        <!-- Logging in SSIS Section -->
                                        <section id="logging-ssis" class="main special">
                                            <header class="major">
                                                <h4>Logging in SSIS</h4>
                                            </header>
                                            <p>Effective logging is crucial for monitoring, debugging, and maintaining ETL processes in SSIS. Here are the steps taken to implement logging in the Retail Sales Data Warehouse project:</p>
                                            
                                            <h5>1. Understanding SSIS Logging Options</h5>
                                            <p>SSIS provides built-in log providers that can log to text files, SQL Server tables, SQL Server Profiler, Windows Event Log, or XML files. Additionally, custom logging can be implemented using script tasks.</p>
                                            
                                            <h5>2. Enabling Built-in SSIS Logging</h5>
                                            <p>To enable SSIS logging, right-click on the Control Flow canvas in your package and select 'Logging'. Configure the log providers, containers, and events you want to log.</p>
                                            
                                            <h5>3. Choosing Logging Events</h5>
                                            <p>Common events to log include OnError, OnWarning, OnInformation, OnPreExecute, OnPostExecute, and OnProgress. These events provide insights into package execution and help identify issues.</p>
                                            
                                            <h5>4. Configuring Log Provider</h5>

                                            <p>Add a Connection Manager to your package pointing to your logging database. In the Logging configuration window, add a new log provider for SQL Server, select the Connection Manager.</p>
                                            
                                            <p>Enable logging in your SSIS package and the next time the package is ran, the default logging table should be in the database you selected under System Tables > dbo.sysssislog</p>

                                            <h5>6. Custom Logging with Script Tasks</h5>
                                            <p>For more granular or custom logging, use Script Tasks to write custom C# or VB.NET code to log specific events or data to a SQL table or a file.</p>
                                            
                                            <h5>7. Monitoring and Maintenance</h5>
                                            <p>Regularly review logs to identify and address issues. Set up alerts or notifications for critical errors or warnings.</p>

                                            <figure>
                                                <img src="images/retail-ssis/sample_log_data.png" alt="Data in dim_product">
                                                <figcaption>Sample log results</figcaption>
                                            </figure>
                                        </section>

                                        <!-- Monitoring and Alerting Section -->
                                        <section id="monitoring-alerting" class="main special">
                                            <header class="major">
                                                <h4>Monitoring and Alerting</h4>
                                            </header>
                                            <p>Monitoring and alerting are crucial for maintaining the health and performance of your ETL processes. Setting up effective monitoring and alerting ensures that you are promptly informed of any critical errors or warnings, allowing you to address issues proactively and minimize downtime.</p>
                                            
                                            <h5>1. Using SQL Server Agent Alerts</h5>
                                            <p>SQL Server Agent allows you to create alerts and configure email notifications for specific events or conditions. This method is commonly used for database-related alerts, including those generated by SSIS packages.</p>
                                            
                                            <h6>Steps to Set Up SQL Server Agent Alerts:</h6>
                                            <h5>1.1 Create an Operator</h5>
                                            <ul>
                                                <li>Open SQL Server Management Studio (SSMS).</li>
                                                <li>Expand the <strong>SQL Server Agent</strong> node.</li>
                                                <li>Right-click <strong>Operators</strong> and select <strong>New Operator</strong>.</li>
                                                <li>Enter the operator's name and email address. This operator will receive the alert notifications.</li>
                                            </ul>
                                            
                                            <h5>1.2 Configure Database Mail</h5>
                                            <ul>
                                                <li>Expand the <strong>Management</strong> node.</li>
                                                <li>Right-click <strong>Database Mail</strong> and select <strong>Configure Database Mail</strong>.</li>
                                                <li>Follow the wizard to set up a new Database Mail profile, including SMTP server details.</li>
                                            </ul>
                                            
                                            <h5>1.3 Create an Alert</h5>
                                            <ul>
                                                <li>Under the <strong>SQL Server Agent</strong> node, right-click <strong>Alerts</strong> and select <strong>New Alert</strong>.</li>
                                                <li>Configure the alert to respond to specific error conditions or performance thresholds. For example:
                                                    <ul>
                                                        <li><strong>Type</strong>: SQL Server event alert.</li>
                                                        <li><strong>Database name</strong>: Select the relevant database.</li>
                                                        <li><strong>Error number</strong>: Specify the error number you want to monitor (e.g., 50000 for custom errors).</li>
                                                    </ul>
                                                </li>
                                                <li>Under the <strong>Response</strong> tab, configure the alert to notify the operator created earlier.</li>
                                            </ul>
                                            
                                            <h5>1.4 Create a Job to Run the SSIS Package</h5>
                                            <ul>
                                                <li>Under the <strong>SQL Server Agent</strong> node, right-click <strong>Jobs</strong> and select <strong>New Job</strong>.</li>
                                                <li>Add a new step to the job to execute the SSIS package.</li>
                                                <li>Under the <strong>Notifications</strong> tab, configure the job to notify the operator on job failure.</li>
                                            </ul>

                                            <h5>2. Using Event Handlers in SSIS</h5>
                                            <p>You can use SSIS event handlers to send email notifications directly from within an SSIS package when specific events occur, such as errors.</p>

                                            <h6>Steps to Set Up Event Handlers:</h6>
                                            <h5>2.1 Open the SSIS Package in SSDT</h5>
                                            <ul>
                                                <li>Open your SSIS package in SQL Server Data Tools (SSDT).</li>
                                            </ul>

                                            <h5>2.2 Add an Event Handler</h5>
                                            <ul>
                                                <li>Click on the <strong>Event Handlers</strong> tab.</li>
                                                <li>From the <strong>Executable</strong> dropdown, select the package or task you want to monitor.</li>
                                                <li>From the <strong>Event Handler</strong> dropdown, select <code>OnError</code> or another event you want to monitor.</li>
                                                <li>Click <strong>Add</strong> to create the event handler.</li>
                                            </ul>

                                            <h5>2.3 Add a Send Mail Task</h5>
                                            <ul>
                                                <li>Drag a <strong>Send Mail Task</strong> onto the Event Handler design surface.</li>
                                                <li>Double-click the <strong>Send Mail Task</strong> to configure it:
                                                    <ul>
                                                        <li><strong>SMTP Connection</strong>: Set up a connection to your SMTP server.</li>
                                                        <li><strong>From</strong>: Enter the sender's email address.</li>
                                                        <li><strong>To</strong>: Enter the recipient's email address.</li>
                                                        <li><strong>Subject</strong>: Enter a subject line (e.g., "SSIS Package Error").</li>
                                                        <li><strong>Message Source</strong>: Enter the body of the email. You can use expressions to include dynamic content such as error messages.</li>
                                                    </ul>
                                                </li>
                                            </ul>

                                            <h5>2.4 Configure the Send Mail Task with Expressions (Optional)</h5>
                                            <ul>
                                                <li>You can use SSIS expressions to include dynamic content in the email body, such as the error description.</li>
                                                <li>In the <strong>Send Mail Task</strong>, click on the <strong>Expressions</strong> property.</li>
                                                <li>Add an expression for the <strong>MessageSource</strong> property to include the system variables like <code>System::ErrorDescription</code>.</li>
                                            </ul>
                                        </section>


                                        <!-- Performance Considerations Section -->
                                        <section id="performance-considerations" class="main special">
                                            <header class="major">
                                                <h4>Performance Considerations</h4>
                                            </header>
                                            <p>Optimizing performance is crucial for the efficient operation of a data warehouse. This section covers key performance considerations, including indexing strategies and avoiding asynchronous transformations in SSIS.</p>
                                            
                                            <h5>Indexes</h5>
                                            <p>Indexes improve query performance by allowing quick data retrieval. Key types include:</p>
                                            <ul style="text-align:left;">
                                                <li><strong>Clustered Indexes:</strong> Create on primary key columns or frequently used columns in range queries.</li>
                                                <li><strong>Non-Clustered Indexes:</strong> Use on columns frequently used in joins, filters, and aggregations.</li>
                                                <li><strong>Covering Indexes:</strong> Include all columns required by a query to reduce table access.</li>
                                                <li><strong>Index Maintenance:</strong> Regularly rebuild or reorganize fragmented indexes.</li>
                                            </ul>

                                            <h5>Avoiding Asynchronous Transformations</h5>
                                            <p>Asynchronous transformations can be performance bottlenecks. Avoid them by using SQL commands:</p>
                                            <ul style="text-align:left;">
                                                <li><strong>Sort Transformation:</strong> Use <code>ORDER BY</code> clause in SQL queries.</li>
                                                <li><strong>Aggregate Transformation:</strong> Perform aggregations in the source query using SQL functions.</li>
                                                <li><strong>Join Transformations:</strong> Use SQL joins in the source query to retrieve joined data directly.</li>
                                            </ul>

                                            <h5>Buffer Management</h5>
                                            <p>Efficient buffer management in SSIS can improve data flow performance. Key practices include:</p>
                                            <ul style="text-align:left;">
                                                <li><strong>Buffer Size:</strong> Increase the default buffer size by adjusting <code>DefaultBufferMaxRows</code> and <code>DefaultBufferSize</code>.</li>
                                                <li><strong>Data Flow Optimization:</strong> Minimize data type conversions and unnecessary transformations.</li>
                                            </ul>

                                            <h5>Additional Considerations</h5>
                                            <ul style="text-align:left;">
                                                <li><strong>Partitioning:</strong> Partition large tables by date, range, or hash.</li>
                                                <li><strong>Parallel Processing:</strong> Enable parallel execution of SSIS packages and tasks.</li>
                                                <li><strong>Avoid Row-by-Row Processing:</strong> Use set-based operations in SQL.</li>
                                                <li><strong>Monitor and Tune Performance:</strong> Use tools like SQL Server Profiler and Performance Monitor.</li>
                                            </ul>
                                        </section>

                                        <!-- Testing Section -->
                                        <section id="testing" class="main special">
                                            <header class="major">
                                                <h4>Testing</h4>
                                            </header>
                                            <p>Testing is a critical phase in the data warehouse development lifecycle. It ensures the accuracy, integrity, and performance of the data warehouse and ETL processes. This section outlines various testing strategies and methodologies employed to validate the Retail Sales Data Warehouse project using SSIS and SQL Server.</p>

                                            <h5>1. Unit Testing</h5>
                                            <p>Unit testing involves testing individual components of the ETL process to ensure they function correctly. In the context of SSIS and SQL Server:</p>
                                            <ul>
                                                <li><strong>SSIS Packages:</strong> Test each SSIS package individually by running the package and verifying the output data at each stage. Use data viewers to inspect data as it flows through the data pipeline.</li>
                                                <li><strong>Stored Procedures and Functions:</strong> Use tSQLt, a unit testing framework for T-SQL, to write and execute tests for stored procedures and functions used in ETL processes.</li>
                                                <li><strong>Data Validity:</strong> Create test cases to validate that the data loaded into staging tables matches the source data in terms of structure and content. Use SQL queries to compare source and destination tables.</li>
                                            </ul>

                                            <h5>2. Integration Testing</h5>
                                            <p>Integration testing ensures that different components of the ETL process work together as expected. This involves testing the entire ETL workflow from source systems to the data warehouse using SSIS:</p>
                                            <ul>
                                                <li><strong>End-to-End Data Flow:</strong> Execute the entire SSIS package workflow and verify that data is correctly extracted, transformed, and loaded into the data warehouse. Use control flow tasks to manage the sequence of operations.</li>
                                                <li><strong>Data Integrity:</strong> Use SQL Server Data Tools (SSDT) to validate data integrity throughout the ETL process. Ensure there are no data loss or corruption by comparing row counts and checksums between source and destination.</li>
                                                <li><strong>Data Consistency:</strong> Check for consistency across different layers of the data warehouse. Use SSIS data flow tasks to perform row-by-row comparisons between staging and final tables.</li>
                                            </ul>

                                            <h5>3. Performance Testing</h5>
                                            <p>Performance testing evaluates the efficiency and scalability of the ETL processes and the data warehouse. This includes:</p>
                                            <ul>
                                                <li><strong>Load Testing:</strong> Simulate high data volumes by running SSIS packages with large datasets. Measure the time taken for ETL processes and ensure they complete within acceptable timeframes. Use SQL Server Profiler to monitor performance.</li>
                                                <li><strong>Query Performance:</strong> Test the performance of queries run against the data warehouse. Use execution plans to identify and optimize slow-running queries.</li>
                                                <li><strong>Resource Utilization:</strong> Monitor CPU, memory, and disk usage during ETL and query operations using Performance Monitor (PerfMon) to identify potential bottlenecks.</li>
                                            </ul>

                                            <h5>4. User Acceptance Testing (UAT)</h5>
                                            <p>User Acceptance Testing (UAT) involves end-users validating the data warehouse to ensure it meets their requirements and expectations:</p>
                                            <ul>
                                                <li><strong>Functional Validation:</strong> Ensure that the data warehouse provides the required reports and data access as specified by the business users. Use SQL Server Reporting Services (SSRS) to generate reports and validate data accuracy.</li>
                                                <li><strong>Usability Testing:</strong> Validate that the data warehouse and BI tools are user-friendly and intuitive for end-users. Gather feedback from users on the ease of use and functionality.</li>
                                                <li><strong>Feedback Loop:</strong> Collect feedback from users and make necessary adjustments to the data warehouse and ETL processes based on their input. Implement changes in SSIS packages and re-test as needed.</li>
                                            </ul>

                                            <h5>5. Data Quality Testing</h5>
                                            <p>Data quality testing ensures that the data in the data warehouse is accurate, complete, and reliable:</p>
                                            <ul>
                                                <li><strong>Data Accuracy:</strong> Verify that the data loaded into the data warehouse matches the source data and is free from errors. Use SQL queries to compare sample data sets from the source and the warehouse.</li>
                                                <li><strong>Data Completeness:</strong> Ensure that all required data has been loaded into the data warehouse, with no missing records or fields. Use row counts and integrity constraints to check for completeness.</li>
                                                <li><strong>Data Consistency:</strong> Check for consistency in data formats, values, and relationships across different tables and layers. Use SSIS data flow transformations to standardize and validate data consistency.</li>
                                            </ul>

                                            <h5>6. Regression Testing</h5>
                                            <p>Regression testing ensures that changes or updates to the ETL processes do not introduce new errors or negatively impact existing functionality:</p>
                                            <ul>
                                                <li><strong>Test Automation:</strong> Use automated testing tools like tSQLt for SQL Server to run regression tests on ETL processes and data warehouse components. Integrate these tests into your continuous integration pipeline.</li>
                                                <li><strong>Version Control:</strong> Maintain version control for ETL scripts and packages using tools like Git to track changes and facilitate rollback if necessary.</li>
                                                <li><strong>Comprehensive Test Cases:</strong> Develop and maintain comprehensive test cases to cover all aspects of the ETL processes and data warehouse functionality. Regularly update test cases to reflect changes in business requirements.</li>
                                            </ul>

                                            <h5>7. Tools and Frameworks</h5>
                                            <p>Various tools and frameworks can be used to facilitate testing in SQL Server and SSIS:</p>
                                            <ul>
                                                <li><strong>tSQLt:</strong> A unit testing framework for T-SQL that allows you to write and execute tests for SQL Server databases.</li>
                                                <li><strong>Visual Studio Test Projects:</strong> Use Visual Studio to create and manage test projects for SSIS packages and SQL Server objects.</li>
                                                <li><strong>SQL Server Data Tools (SSDT):</strong> Provides features for developing, testing, and deploying SQL Server databases and SSIS packages.</li>
                                            </ul>
                                        </section>

                                        <!-- SSAS Section -->
                                        <section id="ssas" class="main special">
                                            <header class="major">
                                                <h4>SQL Server Analysis Services (SSAS)</h4>
                                            </header>
                                            <p>SQL Server Analysis Services (SSAS) is used to build and deploy OLAP cubes and tabular models, which enable advanced data analysis and business intelligence. This section outlines the steps taken to set up and use SSAS in the Retail Sales Data Warehouse project.</p>
                                            
                                            <h5>1. Installation and Setup</h5>
                                            <p>Ensure that SQL Server Data Tools (SSDT) is installed for developing SSAS projects. SSDT can be downloaded from the Microsoft Visual Studio website.</p>
                                            
                                            <h5>2. Creating a New SSAS Project</h5>
                                            <p>In Visual Studio, create a new Analysis Services project. Choose between a Multidimensional and Data Mining Project or a Tabular Project based on the requirements. For beginners, the tabular model is recommended.</p>
                                            
                                            <h5>3. Connecting to the Data Source</h5>
                                            <p>Use the Data Source Wizard in Solution Explorer to connect to the SQL Server database that contains the data warehouse.</p>
                                            
                                            <h5>4. Creating a Data Source View</h5>
                                            <p>Select the necessary tables and views from the database to create a Data Source View using the Data Source View Wizard.</p>
                                            
                                            <h5>5. Designing the Data Model</h5>
                                            <p>Design the data model by dragging and dropping tables and columns. Create relationships, calculated columns, and measures as needed.</p>
                                            
                                            <h5>6. Deploying the SSAS Project</h5>
                                            <p>Configure the deployment settings and deploy the project to the SSAS server.</p>
                                            
                                            <h5>7. Processing the Model</h5>
                                            <p>Process the model to load data into it by right-clicking on the model or cube and selecting "Process". Follow the prompts to complete the process.</p>
                                            
                                            <h5>8. Verifying and Exploring the Model</h5>
                                            <p>Use SQL Server Management Studio (SSMS) to connect to the SSAS server and browse the deployed model or cube. Write MDX or DAX queries to explore the data.</p>
                                        </section>

                                        <!-- Deployment Section -->
                                        <section id="deployment" class="main special">
                                            <header class="major">
                                                <h4>Deployment of SSIS Packages</h4>
                                            </header>
                                            <p>Deployment is a crucial phase in the ETL lifecycle, ensuring that your SSIS packages are properly transferred from the development environment to the production environment. This section covers the different approaches to deploying SSIS packages, the steps involved, and the benefits of proper deployment.</p>

                                            <h5>1. Deployment Approaches</h5>
                                            <p>There are several approaches to deploying SSIS packages, each with its own advantages and use cases:</p>
                                            <ul>
                                                <li><strong>Project Deployment Model:</strong> This is the recommended approach for SQL Server 2012 and later. It allows you to deploy entire SSIS projects, including all packages and parameters, to the SSISDB catalog on the SQL Server instance.</li>
                                                <li><strong>Package Deployment Model:</strong> This approach is suitable for older versions of SQL Server. It allows you to deploy individual packages to the file system or to MSDB, a system database on SQL Server.</li>
                                                <li><strong>File System Deployment:</strong> Deploy packages as files in a directory accessible by the SSIS runtime engine. This method is straightforward but lacks centralized management features.</li>
                                                <li><strong>MSDB Deployment:</strong> Store SSIS packages in the MSDB database on SQL Server. This allows for centralized management but requires more manual configuration compared to the project deployment model.</li>
                                            </ul>

                                            <h5>2. Steps for Deploying SSIS Packages</h5>
                                            <p>Here are the steps involved in deploying SSIS packages using the Project Deployment Model:</p>
                                            <ul>
                                                <li><strong>Build the SSIS Project:</strong>
                                                    <ul>
                                                        <li>In Visual Studio (SSDT), right-click on the SSIS project in Solution Explorer.</li>
                                                        <li>Select "Build" to compile the project and generate the .ispac deployment file.</li>
                                                    </ul>
                                                </li>
                                                <li><strong>Deploy the SSIS Project:</strong>
                                                    <ul>
                                                        <li>Right-click on the project and select "Deploy" to open the Integration Services Deployment Wizard.</li>
                                                        <li>Follow the wizard steps to select the .ispac file, choose the target SQL Server instance, and specify the SSISDB catalog as the destination.</li>
                                                        <li>Review the summary and click "Deploy" to deploy the project to the SSISDB catalog.</li>
                                                    </ul>
                                                </li>
                                                <li><strong>Configure Environments and Parameters:</strong>
                                                    <ul>
                                                        <li>After deployment, use SQL Server Management Studio (SSMS) to configure environments and parameters for your SSIS packages.</li>
                                                        <li>Environments allow you to manage configurations and variables for different runtime scenarios (e.g., development, testing, production).</li>
                                                        <li>Set values for parameters to control package execution without modifying the packages themselves.</li>
                                                    </ul>
                                                </li>
                                            </ul>

                                            <h5>3. Benefits of Proper Deployment</h5>
                                            <p>Proper deployment of SSIS packages offers several benefits:</p>
                                            <ul>
                                                <li><strong>Centralized Management:</strong> The SSISDB catalog provides a centralized location for managing, monitoring, and executing SSIS packages. This simplifies administration and enhances control over your ETL processes.</li>
                                                <li><strong>Version Control:</strong> By using the project deployment model, you can maintain version history of your SSIS packages, making it easier to track changes and revert to previous versions if necessary.</li>
                                                <li><strong>Security:</strong> The SSISDB catalog allows for better security management, including role-based access control and encryption of sensitive data.</li>
                                                <li><strong>Configurability:</strong> Environments and parameters provide flexibility in managing different configurations for various runtime scenarios, ensuring that packages run correctly in different environments without manual modifications.</li>
                                                <li><strong>Monitoring and Logging:</strong> SSISDB offers built-in monitoring and logging capabilities, allowing you to track package execution history, performance, and errors. This aids in troubleshooting and optimizing ETL processes.</li>
                                            </ul>

                                            <h5>4. Best Practices for Deployment</h5>
                                            <p>To ensure a smooth deployment process and reliable operation of your SSIS packages, consider the following best practices:</p>
                                            <ul>
                                                <li><strong>Use Integrated Security:</strong> Whenever possible, use Windows Authentication for connecting to SQL Server to enhance security and simplify credential management.</li>
                                                <li><strong>Parameterize Connections:</strong> Use project parameters to manage connection strings and other configuration settings, allowing for easier environment-specific configurations.</li>
                                                <li><strong>Validate Packages Before Deployment:</strong> Thoroughly test and validate your SSIS packages in a staging or testing environment to ensure they function correctly before deploying them to production.</li>
                                                <li><strong>Automate Deployments:</strong> Use automated deployment tools and scripts to streamline the deployment process and reduce the risk of manual errors.</li>
                                                <li><strong>Monitor Execution:</strong> Regularly monitor the execution of your SSIS packages using SSMS and SSISDB reports to detect and address any issues promptly.</li>
                                            </ul>
                                        </section>

                                        <!-- SSAS Section -->
                                        <section id="ssas" class="main special">
                                            <header class="major">
                                                <h4>SQL Server Analysis Services (SSAS)</h4>
                                            </header>
                                            <p>SQL Server Analysis Services (SSAS) is used to build and deploy OLAP cubes and tabular models, which enable advanced data analysis and business intelligence. This section outlines the explicit steps to set up and use SSAS in the Retail Sales Data Warehouse project.</p>
                                            
                                            <h5>1. Creating a New SSAS Project</h5>
                                            <p>Start by creating a new SSAS project in Visual Studio (SSDT):</p>
                                            <ul>
                                                <li>Open Visual Studio (SSDT).</li>
                                                <li>Click on <strong>File</strong> > <strong>New</strong> > <strong>Project</strong>.</li>
                                                <li>Select <strong>Analysis Services Tabular Project</strong> (recommended for beginners) or <strong>Analysis Services Multidimensional and Data Mining Project</strong>.</li>
                                                <li>Enter a name for your project and click <strong>OK</strong>.</li>
                                            </ul>

                                            <h5>2. Connecting to Your Data Source</h5>
                                            <p>Connect your SSAS project to your data source:</p>
                                            <ul>
                                                <li>In Solution Explorer, right-click on <strong>Data Sources</strong> and select <strong>New Data Source</strong>.</li>
                                                <li>Follow the Data Source Wizard:</li>
                                                <ul>
                                                    <li>Select <strong>Create a data source based on an existing or new connection</strong>.</li>
                                                    <li>Click <strong>New</strong> to create a new connection, enter the server name and select the database (your data warehouse), then click <strong>OK</strong>.</li>
                                                    <li>Click <strong>Next</strong> and then <strong>Finish</strong> to complete the wizard.</li>
                                                </ul>
                                            </ul>

                                            <h5>3. Creating a Data Source View</h5>
                                            <p>Create a Data Source View to define the tables and views to be included in your data model:</p>
                                            <ul>
                                                <li>Right-click on <strong>Data Source Views</strong> in Solution Explorer and select <strong>New Data Source View</strong>.</li>
                                                <li>Follow the Data Source View Wizard:</li>
                                                <ul>
                                                    <li>Select the data source you created in the previous step and click <strong>Next</strong>.</li>
                                                    <li>Select the tables and views you want to include in your data model and click the arrow button to add them, then click <strong>Next</strong>.</li>
                                                    <li>Review the diagram and click <strong>Finish</strong>.</li>
                                                </ul>
                                            </ul>

                                            <h5>4. Designing the Data Model</h5>
                                            <p>Design your data model by creating relationships, calculated columns, and measures:</p>
                                            <ul>
                                                <li><strong>For Tabular Models:</strong>
                                                    <ul>
                                                        <li>Double-click on the <strong>Model.bim</strong> file in Solution Explorer to open the designer.</li>
                                                        <li>Drag and drop tables from the Data Source View to the model designer.</li>
                                                        <li>Define relationships between tables by dragging and dropping columns to create joins.</li>
                                                        <li>Create calculated columns and measures as needed by right-clicking on a table and selecting <strong>New Column</strong> or <strong>New Measure</strong>.</li>
                                                    </ul>
                                                </li>
                                                <li><strong>For Multidimensional Models:</strong>
                                                    <ul>
                                                        <li>Right-click on <strong>Cubes</strong> in Solution Explorer and select <strong>New Cube</strong>.</li>
                                                        <li>Follow the Cube Wizard to select the measures and dimensions for your cube, and click <strong>Next</strong>.</li>
                                                        <li>Review the cube structure and click <strong>Finish</strong>.</li>
                                                        <li>Define dimensions and hierarchies as needed by right-clicking on <strong>Dimensions</strong> and selecting <strong>New Dimension</strong>.</li>
                                                    </ul>
                                                </li>
                                            </ul>

                                            <h5>5. Deploying the SSAS Project</h5>
                                            <p>Deploy your SSAS project to the SSAS server:</p>
                                            <ul>
                                                <li>Right-click on your project in Solution Explorer and select <strong>Properties</strong>.</li>
                                                <li>In the <strong>Configuration Properties</strong> > <strong>Deployment</strong> section, configure the deployment settings:</li>
                                                <ul>
                                                    <li>Set the <strong>Server</strong> property to the name of your SSAS server.</li>
                                                    <li>Set the <strong>Database</strong> property to the name you want for your deployed model or cube.</li>
                                                </ul>
                                                <li>Click <strong>OK</strong> to save the settings.</li>
                                                <li>Right-click on your project and select <strong>Deploy</strong> to deploy the project to the SSAS server.</li>
                                            </ul>

                                            <h5>6. Processing the Model</h5>
                                            <p>Process your SSAS model to load data into it:</p>
                                            <ul>
                                                <li>After deployment, right-click on the model (for tabular) or the cube (for multidimensional) in Solution Explorer and select <strong>Process</strong>.</li>
                                                <li>In the Process dialog, click <strong>Run</strong> to start the processing. This will load data into the model or cube.</li>
                                                <li>Monitor the progress and ensure there are no errors. Once processing is complete, click <strong>Close</strong>.</li>
                                            </ul>

                                            <h5>7. Verifying and Exploring the Model</h5>
                                            <p>Verify and explore your SSAS model using SQL Server Management Studio (SSMS):</p>
                                            <ul>
                                                <li>Open SQL Server Management Studio (SSMS).</li>
                                                <li>Connect to your SSAS server.</li>
                                                <li>Expand the <strong>Databases</strong> node to find your deployed model or cube.</li>
                                                <li>Right-click on the model or cube and select <strong>New Query</strong> > <strong>MDX</strong> (for multidimensional) or <strong>DAX</strong> (for tabular).</li>
                                                <li>Write and execute queries to explore the data and verify that the model is functioning as expected.</li>
                                            </ul>
                                        </section>

                                        <!-- SSRS Section -->
                                        <section id="ssrs" class="main special">
                                            <header class="major">
                                                <h4>SQL Server Reporting Services (SSRS)</h4>
                                            </header>
                                            <p>SQL Server Reporting Services (SSRS) is a server-based report generating software system from Microsoft. It enables the creation, deployment, and management of reports. This section outlines the explicit steps to set up and use SSRS in the Retail Sales Data Warehouse project.</p>
                                            
                                            <h5>1. Creating a New SSRS Project</h5>
                                            <p>Start by creating a new SSRS project in Visual Studio (SSDT):</p>
                                            <ul>
                                                <li>Open Visual Studio (SSDT).</li>
                                                <li>Click on <strong>File</strong> > <strong>New</strong> > <strong>Project</strong>.</li>
                                                <li>Select <strong>Report Server Project</strong> under the Business Intelligence templates.</li>
                                                <li>Enter a name for your project and click <strong>OK</strong>.</li>
                                            </ul>

                                            <h5>2. Adding a Data Source</h5>
                                            <p>Configure a data source for your reports:</p>
                                            <ul>
                                                <li>In Solution Explorer, right-click on <strong>Shared Data Sources</strong> and select <strong>Add New Data Source</strong>.</li>
                                                <li>Name the data source (e.g., <strong>SalesDataSource</strong>).</li>
                                                <li>Click on <strong>Edit</strong> to configure the connection string:</li>
                                                <ul>
                                                    <li>Select your SQL Server instance.</li>
                                                    <li>Select the database that contains your data warehouse.</li>
                                                    <li>Click <strong>OK</strong> to save the connection string.</li>
                                                </ul>
                                                <li>Click <strong>OK</strong> to add the data source.</li>
                                            </ul>

                                            <h5>3. Creating a Shared Dataset</h5>
                                            <p>Create a shared dataset to define the data queries for your reports:</p>
                                            <ul>
                                                <li>Right-click on <strong>Shared Datasets</strong> and select <strong>Add New Dataset</strong>.</li>
                                                <li>Name the dataset (e.g., <strong>SalesDataset</strong>).</li>
                                                <li>Select the shared data source you created earlier.</li>
                                                <li>Write a query to retrieve the data for your reports:</li>
                                                <ul>
                                                    <li>Click on <strong>Query Designer</strong> to build the query graphically, or</li>
                                                    <li>Enter the SQL query directly in the <strong>Query</strong> box.</li>
                                                </ul>
                                                <li>Click <strong>OK</strong> to save the dataset.</li>
                                            </ul>

                                            <h5>4. Creating a New Report</h5>
                                            <p>Create a new report to visualize your data:</p>
                                            <ul>
                                                <li>Right-click on <strong>Reports</strong> in Solution Explorer and select <strong>Add New Report</strong>.</li>
                                                <li>Follow the Report Wizard:</li>
                                                <ul>
                                                    <li>Select the shared dataset you created earlier and click <strong>Next</strong>.</li>
                                                    <li>Choose the report type (e.g., Tabular or Matrix) and click <strong>Next</strong>.</li>
                                                    <li>Design the report layout by selecting fields and arranging them as needed. Click <strong>Next</strong>.</li>
                                                    <li>Choose a style for your report and click <strong>Next</strong>.</li>
                                                    <li>Enter a name for the report and click <strong>Finish</strong>.</li>
                                                </ul>
                                            </ul>

                                            <h5>5. Designing the Report</h5>
                                            <p>Design the report layout and appearance:</p>
                                            <ul>
                                                <li>Use the Report Designer to customize the layout of your report. You can drag and drop fields, add charts, tables, and other visual elements.</li>
                                                <li>Format the report by setting properties for fonts, colors, and borders.</li>
                                                <li>Add interactive features like drill-downs, parameters, and sorting options to enhance report usability.</li>
                                            </ul>

                                            <h5>6. Deploying the Report</h5>
                                            <p>Deploy your report to the SSRS server:</p>
                                            <ul>
                                                <li>Right-click on the project in Solution Explorer and select <strong>Properties</strong>.</li>
                                                <li>In the <strong>TargetServerURL</strong> field, enter the URL of your SSRS server (e.g., <code>http://yourserver/ReportServer</code>).</li>
                                                <li>Click <strong>OK</strong> to save the settings.</li>
                                                <li>Right-click on the project and select <strong>Deploy</strong> to publish the reports to the SSRS server.</li>
                                            </ul>

                                            <h5>7. Viewing the Report</h5>
                                            <p>View and verify your deployed report:</p>
                                            <ul>
                                                <li>Open a web browser and navigate to your SSRS web portal (e.g., <code>http://yourserver/Reports</code>).</li>
                                                <li>Find and open your deployed report.</li>
                                                <li>Verify that the report displays correctly and the data is accurate.</li>
                                            </ul>

                                            <h5>8. Managing Reports</h5>
                                            <p>Manage your reports using the SSRS web portal:</p>
                                            <ul>
                                                <li>Set up subscriptions to automate report delivery via email or file share.</li>
                                                <li>Configure report caching and snapshots to improve performance.</li>
                                                <li>Manage security settings to control access to reports and data sources.</li>
                                            </ul>
                                        </section>

                                        
                                        <!-- Issues Section -->
                                        <section id="issues" class="main special">
                                            <header class="major">
                                                <h4>Issues and Resolutions</h4>
                                            </header>
                                            <p>Throughout the implementation of the data warehouse layer, several challenges were encountered. Addressing these issues was critical to ensure data integrity and the smooth functioning of the ETL processes.</p>
                                            
                                            <h5>Issue: Date Format Inconsistency</h5>
                                            <p>One significant issue encountered was the inconsistency in date formats between the <code>dim_date</code> table and the dates in the dimension and fact tables. The <code>full_date</code> column in the <code>dim_date</code> table was in the format <code>YYYY-MM-DD</code>, while the dates in the other tables included time components, such as <code>YYYY-MM-DD HH:MM:SS.0000000</code>.</p>
                                            
                                            <p>This discrepancy caused problems when establishing foreign key relationships, as the date formats did not match. Maintaining referential integrity between the <code>dim_date</code> table and other tables was crucial after moving data from the staging layer to the dimension and fact tables.</p>
                                            
                                            <h5>Solution: Adding Truncated Date Columns</h5>
                                            <p>To resolve this issue, truncated date columns were added to the relevant tables. These columns contained only the date portion, which allowed for consistent and accurate joins with the <code>full_date</code> column in the <code>dim_date</code> table.</p>
                                            
                                            <p>For example, the original date format in the fact tables was:</p>
                                            <pre><code>2006-01-15 00:00:00.0000000</code></pre>
                                            
                                            <p>After truncation, the format became:</p>
                                            <pre><code>2006-01-15</code></pre>
                                            
                                            <p>This change ensured that referential integrity was maintained when the staging layer data was moved to the dimension and fact tables.</p>
                                            
                                            <figure>

                                            
                                            <p>The steps taken to resolve this issue included:</p>
                                            <ul style="text-align:left;">
                                                <li><strong>Step 1:</strong> Retrieve the list of columns that needed truncation using the 'get column list' task.</li>
                                                <li><strong>Step 2:</strong> Loop through each column in the 'Foreach Loop Container' to add truncated date columns to the tables using the 'add truncated date columns' task.</li>
                                                <li><strong>Step 3:</strong> Set the values of the truncated date columns based on the original date columns using the 'set truncated date columns' task.</li>
                                            </ul>

                                            <h5>Issue: Orphaned Product Rows</h5>
                                            <p>Another significant issue was the presence of orphaned rows in the fact tables where <code>product_id</code> values did not match any entry in the <code>dim_product</code> table. This resulted in <code>product_fk</code> columns in the fact tables being null for these rows, which could lead to referential integrity issues.</p>

                                            <h5>Solution: Adding an Unknown Product Row</h5>
                                            <p>To resolve this, an unknown product row was added to the <code>dim_product</code> table with an ID of <code>-1</code>. All orphaned product rows in the fact tables were then updated to reference this unknown product, ensuring that the <code>product_fk</code> columns would not be null.</p>
                                            
                                            <p>This approach allowed for maintaining referential integrity even when the original product IDs were missing from the <code>dim_product</code> table.</p>
                                            


                                            <p>The steps taken to resolve this issue included:</p>
                                            <ul style="text-align:left;">
                                                <li><strong>Step 1:</strong> Add an unknown product row to the <code>dim_product</code> table with an ID of <code>-1</code>.</li>
                                                <li><strong>Step 2:</strong> Update orphaned product rows in the fact tables to reference this unknown product, ensuring no null values in the <code>product_fk</code> columns.</li>
                                            </ul>
                                        </section>








                                        <!-- Issues and Resolutions -->
                                        <section id="issues-resolutions" class="main special">
                                            <header class="major">
                                                <h4>Issues and Resolutions</h4>
                                            </header>
                                            
                                            <!-- Issue 1: Date Format Inconsistencies -->
                                            <div class="issue">
                                                <h5>Issue 1: Date Format Inconsistencies</h5>
                                                <p><strong>Description:</strong> During the integration process, it was discovered that the <code>full_date</code> column in the <code>dim_date</code> table had a different format compared to the date columns in the dimension and fact tables. The <code>dim_date</code> table used the format <code>YYYY-MM-DD</code>, while the other tables had dates in the format <code>YYYY-MM-DD HH:MM:SS.SSSSSSS</code>.</p>
                                                <p><strong>Solution:</strong> To address this inconsistency and maintain referential integrity, we added truncated date columns to the dimension and fact tables. This involved creating new columns with the truncated dates and populating them with the formatted values.</p>
                                                <p><strong>Steps Taken:</strong></p>
                                                <ul style="text-align:left;">
                                                    <li><strong>Get Column List:</strong> Retrieved a list of all date columns in the staging tables.</li>
                                                    <li><strong>Foreach Loop Container:</strong> Iterated over each table to:
                                                        <ul>
                                                            <li><strong>Add Truncated Date Columns:</strong> Added new columns for truncated dates.</li>
                                                            <li><strong>Set Truncated Date Columns:</strong> Populated the new columns with truncated date values.</li>
                                                        </ul>
                                                    </li>
                                                </ul>
                                                <p><strong>Example of Formatting Differences:</strong></p>
                                                <ul style="text-align:left;">
                                                    <li><code>dim_date.full_date</code>: <code>2014-01-02</code></li>
                                                    <li>Other tables: <code>2006-01-15 00:00:00.0000000</code></li>
                                                </ul>
                                                <figure>
                                                    <img src="images/retail-ssis/truncated_dates_package.png" alt="Data in dim_product">
                                                    <figcaption>Package for adding truncated date columns to resolve date format inconsistencies.</figcaption>
                                                </figure>
                                            </div>

                                            <!-- Issue 2: Orphaned Rows in Fact Tables -->
                                            <div class="issue">
                                                <h5>Issue 2: Orphaned Rows in Fact Tables</h5>
                                                <p><strong>Description:</strong> Some <code>product_id</code> values in the <code>fact_sales</code> table did not have corresponding entries in the <code>dim_product</code> table, resulting in <code>NULL</code> values for the <code>product_fk</code> column in the fact table.</p>
                                                <p><strong>Solution:</strong> To handle these orphaned rows, we added a default row in the <code>dim_product</code> table with an <code>id</code> of <code>-1</code> and updated the orphaned rows in the <code>fact_sales</code> table to reference this default product.</p>
                                                <p><strong>Steps Taken:</strong></p>
                                                <ul style="text-align:left;">
                                                    <li><strong>Add Default Row:</strong> Inserted a row in the <code>dim_product</code> table with <code>product_id = -1</code>.</li>
                                                    <li><strong>Update Orphaned Rows:</strong> Updated rows in the <code>fact_sales</code> table where <code>product_id</code> did not exist in <code>dim_product</code> to use <code>-1</code>.</li>
                                                </ul>

                                                <figure>
                                                    <img src="images/retail-ssis/adding_unknown_product_row.png" alt="Data in dim_product">
                                                    <figcaption>Inserting row to dim product for unknown product.</figcaption>
                                                </figure>
                                                <figure>
                                                    <img src="images/retail-ssis/updating_orphan_rows.png" alt="Data in dim_product">
                                                    <figcaption>Process of updating orphaned product rows to reference the unknown product.</figcaption>
                                                </figure>
                                            </div>

                                            <!-- Issue 3: SSAS Deployment Errors -->
                                            <div class="issue">
                                                <h5>Issue 3: SSAS Deployment Errors</h5>
                                                <p><strong>Description:</strong> While deploying the SSAS project, several errors occurred related to user permissions and server mode.</p>
                                                <p><strong>Errors Encountered:</strong></p>
                                                <ul style="text-align:left;">
                                                    <li>"The user name or password is incorrect."</li>
                                                    <li>"A connection could not be made to the data source."</li>
                                                    <li>"The server is not running in multidimensional mode."</li>
                                                </ul>
                                                <p><strong>Solutions:</strong></p>
                                                <ul style="text-align:left;">
                                                    <li><strong>Impersonation Information:</strong> Ensure the SSAS project uses a username and password for the impersonation information, rather than relying on default settings or a PIN.</li>
                                                    <li><strong>Running in Multidimensional Mode:</strong> Confirm that the SSAS instance is running in multidimensional mode. If the service fails to start after changing the mode, create a new SSAS instance configured for multidimensional mode and migrate the database to this new server.</li>
                                                </ul>
                                                <p><strong>Steps Taken:</strong></p>
                                                <ul style="text-align:left;">
                                                    <li><strong>Change Impersonation Information:</strong> Set the data source to use specific credentials.</li>
                                                    <li><strong>Configure SSAS Instance:</strong> Adjust the SSAS instance to run in multidimensional mode.</li>
                                                    <li><strong>Create New SSAS Instance:</strong> If the existing instance fails, create a new instance and migrate the data.</li>
                                                </ul>
                                                <figure>
                                                    <img src="/images/retail-ssis/deployment_successful.png" alt="SSAS Deployment">
                                                    <figcaption>SSAS Deployment Process Completed Successfully</figcaption>
                                                </figure>
                                            </div>
                                        </section>




					</div>          

				<!-- Footer -->
                <footer id="footer">
                    <section class="alt">
                        <h3>Address</h3>
                        <p>BRIDGE CITY, LA</p>
                    </section>

                    <section>
                        <h3>Email</h3>
                        <p>paulhankins99@gmail.com</p>
                    </section>
                    <section>
                        <h3>Social</h3>
                        <ul class="icons alt">
                            <li><a href="https://www.linkedin.com/in/paul-hankins-075119204/" class="icon brands alt fa-linkedin"><span class="label">Linkedin</span></a></li>
                            <li><a href="https://github.com/Piblo99" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>
                        </ul>
                    </section>
            </footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>
            <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/prism.min.js"></script>
            <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/plugins/toolbar/prism-toolbar.min.js" integrity="sha512-st608h+ZqzliahyzEpETxzU0f7z7a9acN6AFvYmHvpFhmcFuKT8a22TT5TpKpjDa3pt3Wv7Z3SdQBCBdDPhyWA==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
            <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/plugins/copy-to-clipboard/prism-copy-to-clipboard.min.js" integrity="sha512-/kVH1uXuObC0iYgxxCKY41JdWOkKOxorFVmip+YVifKsJ4Au/87EisD1wty7vxN2kAhnWh6Yc8o/dSAXj6Oz7A==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
            <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/plugins/line-numbers/prism-line-numbers.min.js" integrity="sha512-BttltKXFyWnGZQcRWj6osIg7lbizJchuAMotOkdLxHxwt/Hyo+cl47bZU0QADg+Qt5DJwni3SbYGXeGMB5cBcw==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
            <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/components/prism-python.min.js" integrity="sha512-AKaNmg8COK0zEbjTdMHJAPJ0z6VeNqvRvH4/d5M4sHJbQQUToMBtodq4HaV4fa+WV2UTfoperElm66c9/8cKmQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
	</body>
</html>